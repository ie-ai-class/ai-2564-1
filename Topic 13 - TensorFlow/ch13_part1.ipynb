{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import tensorflow as tf\r\n",
    "print('TensorFlow version:', tf.__version__)\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "np.set_printoptions(precision=3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TensorFlow version: 2.5.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating tensors in TensorFlow"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "a = np.array([1, 2, 3], dtype=np.int32)\r\n",
    "b = [4, 5, 6]\r\n",
    "\r\n",
    "t_a = tf.convert_to_tensor(a)\r\n",
    "t_b = tf.convert_to_tensor(b)\r\n",
    "\r\n",
    "print(t_a)\r\n",
    "print(t_b)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([4 5 6], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "tf.is_tensor(a), tf.is_tensor(t_a)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "t_ones = tf.ones((2, 3))\r\n",
    "\r\n",
    "t_ones.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TensorShape([2, 3])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "t_ones.numpy()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "const_tensor = tf.constant([1.2, 5, np.pi], dtype=tf.float32)\r\n",
    "\r\n",
    "print(const_tensor)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([1.2   5.    3.142], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Manipulating the data type and shape of a tensor"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "t_a_new = tf.cast(t_a, tf.int64)\r\n",
    "\r\n",
    "print(t_a_new.dtype)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<dtype: 'int64'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "t = tf.random.uniform(shape=(3, 5))\r\n",
    "\r\n",
    "t_tr = tf.transpose(t)\r\n",
    "print(t.shape, ' --> ', t_tr.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(3, 5)  -->  (5, 3)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "t = tf.zeros((30,))\r\n",
    "\r\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\r\n",
    "\r\n",
    "print(t_reshape.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(5, 6)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "t = tf.zeros((1, 2, 1, 4, 1))\r\n",
    "\r\n",
    "t_sqz = tf.squeeze(t, axis=(2, 4))\r\n",
    "\r\n",
    "print(t.shape, ' --> ', t_sqz.shape)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(1, 2, 1, 4, 1)  -->  (1, 2, 4)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Applying mathematical operations to tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "tf.random.set_seed(1)\r\n",
    "\r\n",
    "t1 = tf.random.uniform(shape=(5, 2), \r\n",
    "                       minval=-1.0,\r\n",
    "                       maxval=1.0)\r\n",
    "\r\n",
    "t2 = tf.random.normal(shape=(5, 2), \r\n",
    "                      mean=0.0,\r\n",
    "                      stddev=1.0)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "print(t1.numpy())\r\n",
    "print(t2.numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-0.67   0.803]\n",
      " [ 0.262 -0.131]\n",
      " [-0.416  0.285]\n",
      " [ 0.952 -0.13 ]\n",
      " [ 0.32   0.21 ]]\n",
      "[[ 0.403 -1.088]\n",
      " [-0.063  1.337]\n",
      " [ 0.712 -0.489]\n",
      " [-0.764 -1.037]\n",
      " [-1.252  0.021]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "# Elementwise multiplication\r\n",
    "t3 = tf.multiply(t1, t2).numpy()\r\n",
    "print(t3)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-0.27  -0.874]\n",
      " [-0.017 -0.175]\n",
      " [-0.296 -0.139]\n",
      " [-0.727  0.135]\n",
      " [-0.401  0.004]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "t4 = tf.math.reduce_mean(t1, axis=0)\r\n",
    "\r\n",
    "print(t4)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor([0.09  0.207], shape=(2,), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\r\n",
    "\r\n",
    "print(t5.numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-1.144  1.115 -0.87  -0.321  0.856]\n",
      " [ 0.248 -0.191  0.25  -0.064 -0.331]\n",
      " [-0.478  0.407 -0.436  0.022  0.527]\n",
      " [ 0.525 -0.234  0.741 -0.593 -1.194]\n",
      " [-0.099  0.26   0.125 -0.462 -0.396]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\r\n",
    "\r\n",
    "print(t6.numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[-1.711  0.302]\n",
      " [ 0.371 -1.049]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\r\n",
    "\r\n",
    "print(norm_t1)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1.046 0.293 0.504 0.96  0.383]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "np.sqrt(np.sum(np.square(t1), axis=1))"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.046, 0.293, 0.504, 0.96 , 0.383], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Split, stack, and concatenate tensors"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "tf.random.set_seed(1)\r\n",
    "\r\n",
    "t = tf.random.uniform((6,))\r\n",
    "\r\n",
    "print(t.numpy())\r\n",
    "\r\n",
    "t_splits = tf.split(t, 3)\r\n",
    "\r\n",
    "[item.numpy() for item in t_splits]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292 0.643]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0.165, 0.901], dtype=float32),\n",
       " array([0.631, 0.435], dtype=float32),\n",
       " array([0.292, 0.643], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "tf.random.set_seed(1)\r\n",
    "t = tf.random.uniform((5,))\r\n",
    "\r\n",
    "print(t.numpy())\r\n",
    "\r\n",
    "t_splits = tf.split(t, num_or_size_splits=[3, 2])\r\n",
    "\r\n",
    "[item.numpy() for item in t_splits]"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.165 0.901 0.631 0.435 0.292]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[array([0.165, 0.901, 0.631], dtype=float32),\n",
       " array([0.435, 0.292], dtype=float32)]"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "t = tf.random.uniform((6,4))\r\n",
    "\r\n",
    "print(t)\r\n",
    "\r\n",
    "t_splits = tf.split(t, axis=1, num_or_size_splits=2)\r\n",
    "\r\n",
    "for item in t_splits:\r\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[0.51  0.444 0.409 0.992]\n",
      " [0.689 0.346 0.436 0.601]\n",
      " [0.457 0.753 0.188 0.549]\n",
      " [0.549 0.55  0.28  0.109]\n",
      " [0.631 0.874 0.532 0.561]\n",
      " [0.294 0.928 0.11  0.964]], shape=(6, 4), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.51  0.444]\n",
      " [0.689 0.346]\n",
      " [0.457 0.753]\n",
      " [0.549 0.55 ]\n",
      " [0.631 0.874]\n",
      " [0.294 0.928]], shape=(6, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.409 0.992]\n",
      " [0.436 0.601]\n",
      " [0.188 0.549]\n",
      " [0.28  0.109]\n",
      " [0.532 0.561]\n",
      " [0.11  0.964]], shape=(6, 2), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "A = tf.ones((3,))\r\n",
    "B = tf.zeros((2,))\r\n",
    "\r\n",
    "C = tf.concat([A, B], axis=0)\r\n",
    "print(C.numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 1. 1. 0. 0.]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "A = tf.ones((3,))\r\n",
    "B = tf.zeros((3,))\r\n",
    "\r\n",
    "S = tf.stack([A, B], axis=1)\r\n",
    "print(S.numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Building input pipelines using tf.data: The TensorFlow Dataset API"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a TensorFlow Dataset from existing tensors "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0]\r\n",
    "\r\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\r\n",
    "\r\n",
    "print(ds)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.float32>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "for item in ds:\r\n",
    "    print(item)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(1.2, shape=(), dtype=float32)\n",
      "tf.Tensor(3.4, shape=(), dtype=float32)\n",
      "tf.Tensor(7.5, shape=(), dtype=float32)\n",
      "tf.Tensor(4.1, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "ds_batch = ds.batch(3)\r\n",
    "\r\n",
    "for i, elem in enumerate(ds_batch, 1):\r\n",
    "    print('batch {}:'.format(i), elem.numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "batch 1: [1.2 3.4 7.5]\n",
      "batch 2: [4.1 5.  1. ]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Combining two tensors into a joint dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "tf.random.set_seed(1)\r\n",
    "\r\n",
    "t_x = tf.random.uniform([4, 3], dtype=tf.float32)\r\n",
    "t_y = tf.range(4)\r\n",
    "\r\n",
    "print(t_x)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]\n",
      " [0.605 0.637 0.614]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices(tf.random.uniform([9, 3], dtype=tf.float32))\r\n",
    "dsBatch = ds.batch(3)\r\n",
    "\r\n",
    "\r\n",
    "for i in dsBatch:\r\n",
    "    print(i)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tf.Tensor(\n",
      "[[0.992 0.989 0.57 ]\n",
      " [0.793 0.09  0.842]\n",
      " [0.822 0.859 0.146]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.902 0.418 0.756]\n",
      " [0.318 0.754 0.027]\n",
      " [0.626 0.067 0.368]], shape=(3, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.8   0.261 0.37 ]\n",
      " [0.726 0.628 0.348]\n",
      " [0.411 0.031 0.991]], shape=(3, 3), dtype=float32)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)\r\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)\r\n",
    "    \r\n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))\r\n",
    "\r\n",
    "for example in ds_joint:\r\n",
    "    print('  x: ', example[0].numpy(), \r\n",
    "          '  y: ', example[1].numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  x:  [0.165 0.901 0.631]   y:  0\n",
      "  x:  [0.435 0.292 0.643]   y:  1\n",
      "  x:  [0.976 0.435 0.66 ]   y:  2\n",
      "  x:  [0.605 0.637 0.614]   y:  3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "source": [
    "## method 2:\r\n",
    "ds_joint = tf.data.Dataset.from_tensor_slices((t_x, t_y))\r\n",
    "\r\n",
    "for example in ds_joint:\r\n",
    "    print('  x: ', example[0].numpy(), \r\n",
    "          '  y: ', example[1].numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  x:  [0.165 0.901 0.631]   y:  0\n",
      "  x:  [0.435 0.292 0.643]   y:  1\n",
      "  x:  [0.976 0.435 0.66 ]   y:  2\n",
      "  x:  [0.605 0.637 0.614]   y:  3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "source": [
    "ds_trans = ds_joint.map(lambda x, y: (x*2-1.0, y))\r\n",
    "\r\n",
    "for example in ds_trans:\r\n",
    "    print('  x: ', example[0].numpy(), \r\n",
    "          '  y: ', example[1].numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  x:  [-0.67   0.803  0.262]   y:  0\n",
      "  x:  [-0.131 -0.416  0.285]   y:  1\n",
      "  x:  [ 0.952 -0.13   0.32 ]   y:  2\n",
      "  x:  [0.21  0.273 0.229]   y:  3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Shuffle, batch, and repeat"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "source": [
    "tf.random.set_seed(1)\r\n",
    "ds = ds_joint.shuffle(buffer_size=len(t_x))\r\n",
    "\r\n",
    "for example in ds:\r\n",
    "    print('  x: ', example[0].numpy(), \r\n",
    "          '  y: ', example[1].numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "  x:  [0.976 0.435 0.66 ]   y:  2\n",
      "  x:  [0.435 0.292 0.643]   y:  1\n",
      "  x:  [0.165 0.901 0.631]   y:  0\n",
      "  x:  [0.605 0.637 0.614]   y:  3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "ds = ds_joint.batch(batch_size=3,\r\n",
    "                    drop_remainder=False)\r\n",
    "\r\n",
    "batch_x, batch_y = next(iter(ds))\r\n",
    "\r\n",
    "print('Batch-x: \\n', batch_x.numpy())\r\n",
    "\r\n",
    "print('Batch-y:   ', batch_y.numpy())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch-x: \n",
      " [[0.165 0.901 0.631]\n",
      " [0.435 0.292 0.643]\n",
      " [0.976 0.435 0.66 ]]\n",
      "Batch-y:    [0 1 2]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds = ds_joint.batch(3).repeat(count=2)\r\n",
    "\r\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\r\n",
    "    print(i, batch_x.shape, batch_y.numpy())\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds = ds_joint.repeat(count=2).batch(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 1: shuffle -> batch -> repeat\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 1: shuffle -> batch -> repeat\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(20)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 2: batch -> shuffle -> repeat\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 2: batch -> shuffle -> repeat\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(20)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creating a dataset from files on your local storage disk"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pathlib\n",
    "\n",
    "imgdir_path = pathlib.Path('cat_dog_images')\n",
    "\n",
    "file_list = sorted([str(path) for path in imgdir_path.glob('*.jpg')])\n",
    "\n",
    "print(file_list)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i,file in enumerate(file_list):\n",
    "    img_raw = tf.io.read_file(file)\n",
    "    img = tf.image.decode_image(img_raw)\n",
    "    print('Image shape: ', img.shape)\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(os.path.basename(file), size=15)\n",
    "    \n",
    "# plt.savefig('ch13-catdot-examples.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "labels = [1 if 'dog' in os.path.basename(file) else 0\n",
    "          for file in file_list]\n",
    "print(labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_files_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    (file_list, labels))\n",
    "\n",
    "for item in ds_files_labels:\n",
    "    print(item[0].numpy(), item[1].numpy())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def load_and_preprocess(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    image /= 255.0\n",
    "\n",
    "    return image, label\n",
    "\n",
    "img_width, img_height = 120, 80\n",
    "\n",
    "ds_images_labels = ds_files_labels.map(load_and_preprocess)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i,example in enumerate(ds_images_labels):\n",
    "    print(example[0].shape, example[1].numpy())\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(example[0])\n",
    "    ax.set_title('{}'.format(example[1].numpy()), \n",
    "                 size=15)\n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('ch13-catdog-dataset.pdf')\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fetching available datasets from the tensorflow_datasets library"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! pip install tensorflow-datasets"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(len(tfds.list_builders()))\n",
    "print(tfds.list_builders()[:5])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## Run this to see the full list:\n",
    "tfds.list_builders()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fetching CelebA dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "celeba_bldr = tfds.builder('celeb_a')\n",
    "\n",
    "print(celeba_bldr.info.features)\n",
    "print('\\n', 30*\"=\", '\\n')\n",
    "print(celeba_bldr.info.features.keys())\n",
    "print('\\n', 30*\"=\", '\\n')\n",
    "print(celeba_bldr.info.features['image'])\n",
    "print('\\n', 30*\"=\", '\\n')\n",
    "print(celeba_bldr.info.features['attributes'].keys())\n",
    "print('\\n', 30*\"=\", '\\n')\n",
    "print(celeba_bldr.info.citation)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Download the data, prepare it, and write it to disk\n",
    "celeba_bldr.download_and_prepare()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load data from disk as tf.data.Datasets\n",
    "datasets = celeba_bldr.as_dataset(shuffle_files=False)\n",
    "\n",
    "datasets.keys()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#import tensorflow as tf\n",
    "ds_train = datasets['train']\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "\n",
    "example = next(iter(ds_train))\n",
    "print(type(example))\n",
    "print(example.keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_train = ds_train.map(lambda item: \n",
    "     (item['image'], tf.cast(item['attributes']['Male'], tf.int32)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_train = ds_train.batch(18)\n",
    "images, labels = next(iter(ds_train))\n",
    "\n",
    "print(images.shape, labels)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i,(image,label) in enumerate(zip(images, labels)):\n",
    "    ax = fig.add_subplot(3, 6, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(image)\n",
    "    ax.set_title('{}'.format(label), size=15)\n",
    "    \n",
    "\n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Alternative ways for loading a dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "mnist, mnist_info = tfds.load('mnist', with_info=True,\n",
    "                              shuffle_files=False)\n",
    "\n",
    "print(mnist_info)\n",
    "\n",
    "print(mnist.keys())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "ds_train = mnist['train']\n",
    "\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "\n",
    "ds_train = ds_train.map(lambda item: \n",
    "     (item['image'], item['label']))\n",
    "\n",
    "ds_train = ds_train.batch(10)\n",
    "batch = next(iter(ds_train))\n",
    "print(batch[0].shape, batch[1])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i,(image,label) in enumerate(zip(batch[0], batch[1])):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(image[:, :, 0], cmap='gray_r')\n",
    "    ax.set_title('{}'.format(label), size=15)\n",
    "    \n",
    "plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "---\n",
    "\n",
    "Readers may ignore the next cell."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "! python ../.convert_notebook_to_script.py --input ch13_part1.ipynb --output ch13_part1.py"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('tf': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "interpreter": {
   "hash": "24f3f298f882695df387f3d4878b093c87e5aba98bd6b9b541caa240c812a45a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}