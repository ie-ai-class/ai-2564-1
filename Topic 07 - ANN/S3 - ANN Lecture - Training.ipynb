{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import os, time\r\n",
    "import tensorflow as tf\r\n",
    "from tensorflow.keras.models import Model\r\n",
    "from tensorflow.keras.layers import Input\r\n",
    "from tensorflow.keras.layers import Dense\r\n",
    "from tensorflow.keras.layers.experimental import preprocessing\r\n",
    "from tensorflow.keras.callbacks import EarlyStopping\r\n",
    "from tensorflow.keras.layers import BatchNormalization\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nPoint = 1000\r\n",
    "X = np.linspace(0,4*np.pi, nPoint)\r\n",
    "y = np.sin(X) + np.random.random((nPoint,))/2 + X*3/4 + np.cos(3/2*X)\r\n",
    "X = X[..., np.newaxis]\r\n",
    "\r\n",
    "fig, ax = plt.subplots()\r\n",
    "ax.plot(X,y,'*--')\r\n",
    "ax.set_title('Actual Data')\r\n",
    "ax.set_xlabel('X')\r\n",
    "ax.set_ylabel('Y')\r\n",
    "plt.show()\r\n",
    "#fig.savefig('Fig-actual.png', dpi=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def model_linear(X):\r\n",
    "\r\n",
    "    normalizer = preprocessing.Normalization(axis=-1)\r\n",
    "    normalizer.adapt(X)\r\n",
    "\r\n",
    "    layerIn = Input(shape=(1,))\r\n",
    "    layerMid = normalizer(layerIn)\r\n",
    "    layerOut = Dense(1, kernel_initializer='normal')(layerMid)\r\n",
    "    model = Model(inputs=layerIn, outputs=layerOut)\r\n",
    "    return model\r\n",
    "\r\n",
    "def model_nonLinear(X, layerShapes, activation):\r\n",
    "\r\n",
    "    normalizer = preprocessing.Normalization(axis=-1)\r\n",
    "    normalizer.adapt(X)\r\n",
    "\r\n",
    "    layerIn = Input(shape=(1,))\r\n",
    "    layerMid = normalizer(layerIn)\r\n",
    "    for layerShape in layerShapes:\r\n",
    "        layerMid = Dense(layerShape, activation=activation, kernel_initializer='normal')(layerMid)\r\n",
    "        # layerMid = BatchNormalization()(layerMid)\r\n",
    "    layerOut = Dense(1, kernel_initializer='normal')(layerMid)\r\n",
    "    model = Model(inputs=layerIn, outputs=layerOut)\r\n",
    "    return model"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def get_latest_checkpoint_folder(path):\r\n",
    "    a = os.listdir(path)\r\n",
    "    if a:\r\n",
    "        a.sort()\r\n",
    "        return os.path.join(path, a[-1])\r\n",
    "    else:\r\n",
    "        return ''"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def train_model(X, y, model, modelParam):\r\n",
    "\r\n",
    "    #Check if model exist\r\n",
    "    if not(os.path.exists(modelParam['checkpoint_dirname'])):\r\n",
    "        os.mkdir(modelParam['checkpoint_dirname'])\r\n",
    "        latestDir = ''\r\n",
    "    else:\r\n",
    "        latestDir = get_latest_checkpoint_folder(modelParam['checkpoint_dirname'])\r\n",
    "        \r\n",
    "    if latestDir:        \r\n",
    "        print(f'Load model from {latestDir}')\r\n",
    "        latestFile = tf.train.latest_checkpoint(latestDir)\r\n",
    "        model.load_weights(latestFile)\r\n",
    "    else:\r\n",
    "        print('Load new model')\r\n",
    "\r\n",
    "    if 'patience' in modelParam.keys():\r\n",
    "        patience = modelParam['patience']\r\n",
    "    else:\r\n",
    "        patience = 30\r\n",
    "        \r\n",
    "    earlyStoppingCallback = EarlyStopping(monitor='loss', patience=patience, min_delta=0)\r\n",
    "\r\n",
    "    checkpointFilepath = os.path.join(\r\n",
    "                                modelParam['checkpoint_dirname'], \r\n",
    "                                time.strftime(\"%Y-%m-%d-%H-%M-%S\"),\r\n",
    "                                modelParam['checkpoint_filename'])\r\n",
    "    checkpointCallback = tf.keras.callbacks.ModelCheckpoint(\r\n",
    "        filepath=checkpointFilepath,\r\n",
    "        save_weights_only=True,\r\n",
    "        monitor='loss',\r\n",
    "        mode='min',\r\n",
    "        save_best_only=True)\r\n",
    "\r\n",
    "    model.compile(\r\n",
    "        optimizer=tf.optimizers.Adam(learning_rate=modelParam['learning_rate']),\r\n",
    "        loss='mean_absolute_error', metrics=['mean_absolute_percentage_error'])\r\n",
    "\r\n",
    "    history = model.fit(X, y, epochs=1000, callbacks=[checkpointCallback, earlyStoppingCallback ], verbose=0)\r\n",
    "    return history"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_loss(history):\r\n",
    "    hist = history.history\r\n",
    "    x_arr = np.arange(len(hist['loss'])) + 1\r\n",
    "    fig = plt.figure(figsize=(12, 4))\r\n",
    "    ax = fig.add_subplot(1, 2, 1)\r\n",
    "    ax.plot(x_arr, hist['loss'], '-o', label='Train loss')\r\n",
    "    ax.set_xlabel('Epoch', size=15)\r\n",
    "    ax.set_ylabel('Loss', size=15)\r\n",
    "    ax.legend(fontsize=15)\r\n",
    "\r\n",
    "    ax = fig.add_subplot(1, 2, 2)\r\n",
    "    ax.plot(x_arr, hist['mean_absolute_percentage_error'], '-o', label='Train loss')\r\n",
    "    ax.set_xlabel('Epoch', size=15)\r\n",
    "    ax.set_ylabel('MAPE', size=15)\r\n",
    "    ax.legend(fontsize=15)\r\n",
    "    plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def plot_predict(X, y, model, plotParam):\r\n",
    "    y_pred = model(X)\r\n",
    "    fig ,ax = plt.subplots()\r\n",
    "    ax.plot(X,y)\r\n",
    "    ax.plot(X,y_pred)\r\n",
    "    ax.set_title(plotParam['title'])\r\n",
    "    ax.set_xlabel('X')\r\n",
    "    ax.set_ylabel('Y')\r\n",
    "    ax.legend(['Actual', 'Fitting'])\r\n",
    "    plt.show()\r\n",
    "    fig.savefig(plotParam['filePathName'], dpi=300)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "cwd = os.getcwd()\r\n",
    "modelParams = {\r\n",
    "    'linear': {\r\n",
    "            'model': model_linear(X),\r\n",
    "            'checkpoint_dirname': os.path.join(cwd,'tmp', 'linear'),\r\n",
    "            'checkpoint_filename':'cp-{epoch:04d}.ckpt',\r\n",
    "            'learning_rate': 0.1},\r\n",
    "    'S1': {\r\n",
    "            'model': model_nonLinear(X, [1], 'sigmoid'),\r\n",
    "            'checkpoint_dirname': os.path.join(cwd,'tmp', 'S1'),\r\n",
    "            'checkpoint_filename':'cp-{epoch:04d}.ckpt',\r\n",
    "            'learning_rate': 0.1},       \r\n",
    "    'S2': {\r\n",
    "            'model': model_nonLinear(X, [10], 'sigmoid'),\r\n",
    "            'checkpoint_dirname': os.path.join(cwd,'tmp', 'S2'),\r\n",
    "            'checkpoint_filename':'cp-{epoch:04d}.ckpt',\r\n",
    "            'learning_rate': 0.1},         \r\n",
    "   'S3': {\r\n",
    "            'model': model_nonLinear(X, [64, 64], 'sigmoid'),\r\n",
    "            'checkpoint_dirname': os.path.join(cwd,'tmp', 'S3'),\r\n",
    "            'checkpoint_filename':'cp-{epoch:04d}.ckpt',\r\n",
    "            'learning_rate': 0.1},   \r\n",
    "   'S4': {\r\n",
    "            'model': model_nonLinear(X, [128, 64, 10], 'sigmoid'),\r\n",
    "            'checkpoint_dirname': os.path.join(cwd,'tmp', 'S4'),\r\n",
    "            'checkpoint_filename':'cp-{epoch:04d}.ckpt',\r\n",
    "            'learning_rate': 0.01,\r\n",
    "            'patience': 100\r\n",
    "            }, \r\n",
    "   'S5': {\r\n",
    "            'model': model_nonLinear(X, [256, 128, 64, 32, 10], 'relu'),\r\n",
    "            'checkpoint_dirname': os.path.join(cwd,'tmp', 'S5'),\r\n",
    "            'checkpoint_filename':'cp-{epoch:04d}.ckpt',\r\n",
    "            'learning_rate': 0.01,\r\n",
    "            'patience': 200\r\n",
    "            },   \r\n",
    "   'S6': {\r\n",
    "            'model': model_nonLinear(X, [256, 256, 128, 64, 32, 16], 'relu'),\r\n",
    "            'checkpoint_dirname': os.path.join(cwd,'tmp', 'S6'),\r\n",
    "            'checkpoint_filename':'cp-{epoch:04d}.ckpt',\r\n",
    "            'learning_rate': 0.001,\r\n",
    "            'patience': 300\r\n",
    "            },  \r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# runMode = 'train'\r\n",
    "runMode = 'plot'\r\n",
    "\r\n",
    "#modelName = 'linear'\r\n",
    "#modelName = 'S1'\r\n",
    "#modelName = 'S2'\r\n",
    "#modelName = 'S3'\r\n",
    "#modelName = 'S4'\r\n",
    "#modelName = 'S5'\r\n",
    "modelName = 'S6'\r\n",
    "\r\n",
    "plotParam = {'title': modelName.title(), 'filePathName': os.path.join(cwd,f'Fig-{modelName}.png')}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "tf.keras.backend.clear_session()\r\n",
    "modelParam = modelParams[modelName]\r\n",
    "model = modelParam['model']\r\n",
    "model.summary()\r\n",
    "\r\n",
    "if runMode == 'train':\r\n",
    "    history = train_model(X, y, model, modelParam)\r\n",
    "    plot_loss(history)\r\n",
    "elif runMode == 'plot':\r\n",
    "    latestDir = get_latest_checkpoint_folder(modelParam['checkpoint_dirname'])\r\n",
    "    print(f'Load model from {latestDir}')\r\n",
    "    latestFile = tf.train.latest_checkpoint(latestDir)\r\n",
    "    model.load_weights(latestFile)\r\n",
    "    plot_predict(X, y, model, plotParam)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.11 64-bit ('tf': conda)"
  },
  "interpreter": {
   "hash": "b4a387497f54fd22d04ab06f3cac2b317ccdf5aa3fbc31422dd91bb954740c85"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}